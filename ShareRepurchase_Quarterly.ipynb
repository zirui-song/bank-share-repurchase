{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec90a022-c9fe-4c5a-9e26-e1fa4431af7b",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "91db0dcd-0bb8-402c-a7d8-12849d07727d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "#%% Packages \n",
    "import wrds\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "import time\n",
    "from time import strptime, strftime\n",
    "\n",
    "# Setups\n",
    "pd.set_option(\"display.max_rows\", 200) # max number or rows to be displayed \n",
    "#%% Set WRDS Connection\n",
    "db = wrds.Connection(wrds_username='zrsong') # make sure to configure wrds connector before hand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2b7aa-4114-4370-aa4a-3f57fa42889a",
   "metadata": {},
   "source": [
    "Load in Compustat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "12370a39-c0b8-4e98-af2b-b08a7a434654",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                tables\n",
       "0            aco_amda\n",
       "1            aco_imda\n",
       "2         aco_indfnta\n",
       "3         aco_indfntq\n",
       "4       aco_indfntytd\n",
       "..                ...\n",
       "282      wrds_seg_geo\n",
       "283  wrds_seg_product\n",
       "284    wrds_segmerged\n",
       "285        xfl_column\n",
       "286         xfl_table\n",
       "\n",
       "[287 rows x 1 columns]>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compm_tables = db.list_tables(library=\"comp\") # compd: Compustat daily update \n",
    "pd.DataFrame({'tables':compm_tables}).head # Transform libs to a Pandas data frame to have a better display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import thomson reuters 13f data from WRDS\n",
    "# tr_13f: Thomson Reuters 13F Holdings Data\n",
    "# tr_13f_tables = db.list_tables(library=\"tr_13f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c43b813e-86f4-4906-ad1a-4335fd8e9309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/wrds/sql.py:580: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([full_df, chunk])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/wrds/sql.py:580: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([full_df, chunk])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/wrds/sql.py:580: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([full_df, chunk])\n"
     ]
    }
   ],
   "source": [
    "fund_table = 'fundq'\n",
    "\n",
    "varlist = ['conm', 'tic', 'cusip','fyearq', 'fqtr', 'fyr', 'atq','capxy', 'ceqq', 'cogsq', \n",
    "           'cshoq', 'dlcq', 'dlcchy','dlttq', 'dpq', 'ibq', 'itccy', 'fic',\n",
    "           'ltq', 'mibq', 'niq', 'prstkccy', 'pstkq', 'req', 'revtq', 'saleq',\n",
    "           'seqq', 'txdbq', 'txdiq', 'txditcq', 'wcapchy', 'xinty', 'xrdq', 'xsgaq',\n",
    "           'mkvaltq', 'epspxq', 'epsfxq', 'ajexq', 'prccq', 'oancfy', 'ivncfy', 'rdq', 'prstkcy', 'sstky', 'tstkq', 'dvpy', 'dvy']\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT gvkey, datadate, {}\n",
    "           FROM comp.{}\n",
    "           WHERE datafmt = 'STD'\n",
    "           AND popsrc = 'D'\n",
    "           AND indfmt = 'INDL'\n",
    "           AND consol = 'C'\n",
    "           AND fyearq <= 2023\n",
    "           AND fyearq >= 1988;\"\"\".format(\", \".join(varlist), fund_table)\n",
    "\n",
    "compq = db.raw_sql(query, date_cols=['datadate'])\n",
    "\n",
    "del(fund_table, varlist, query)\n",
    "# output csv. format\n",
    "# compq.to_csv(\"compustat_quarterly.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether gvkey datadate is a unique key\n",
    "compq.duplicated(['gvkey', 'datadate']).sum()\n",
    "compq[compq.duplicated(['gvkey', 'fyearq', 'fqtr'])]\n",
    "# How to deal with duplicates? Keep last available entry (datadate)\n",
    "compq.dropna(subset=['fyearq','fqtr'], inplace=True)\n",
    "compq.sort_values(['gvkey','fyearq','fqtr','atq'], inplace=True)\n",
    "compq = compq[~compq.duplicated(['gvkey', 'fyearq','fqtr'], keep='first')]\n",
    "compq.duplicated(['gvkey', 'fyearq','fqtr']).sum()\n",
    "\n",
    "# output pickle format\n",
    "compq.to_pickle(\"compustat_quarterly.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c7e2f36e-f195-4c60-8dee-fe180e668287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only naics code 52 (merge with compa annual data to get naics code) using compa_annual.pkl in the same folder\n",
    "compa = pd.read_pickle(\"compa_annual.pkl\")\n",
    "compa = compa[['gvkey', 'fyear', 'naicsh', 'prstkc', 'sstk','dvp','tstk']]\n",
    "# merge compq and compa\n",
    "# rename fyear fyearq to merge\n",
    "compa.rename(columns={'fyear':'fyearq'}, inplace=True)\n",
    "compq1 = pd.merge(compq, compa, how='left', on=['gvkey', 'fyearq'])\n",
    "# keep only those with six-digit naics code that starts with 52 (change to string first)\n",
    "compq1['naicsh'] = compq1['naicsh'].astype(str)\n",
    "compq1 = compq1[compq1['naicsh'].str.startswith('52')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "compq = pd.read_pickle(\"compustat_quarterly.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of observations in compq\n",
    "compq1.shape[0]\n",
    "compq1.duplicated(['gvkey', 'fyearq','fqtr']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save compq to csv file\n",
    "compq1.to_csv(\"compustat_quarterly.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
